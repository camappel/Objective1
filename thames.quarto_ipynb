{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Thames Barrier\"\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This document provides a complete analysis workflow for the Thames barrier system, combining barrier closure analysis, tide gauge data processing, tidal analysis, and visualization. The analysis covers the period from 1986 to 2024 and includes:\n",
        "\n",
        "1. **Barrier Closure Analysis**: Loading and analyzing past barrier closure dates, counting closures per water year, and calculating statistics\n",
        "2. **Tide Gauge Data Processing**: Loading and combining tide gauge data from multiple sources\n",
        "3. **Tidal Analysis**: Performing harmonic tidal decomposition and generating predicted astronomical tides\n",
        "4. **Visualization**: Creating comprehensive visualizations showing predicted high waters, observed water levels, and barrier closures\n",
        "\n",
        "Water years run from July 1 to June 30, which is more appropriate for coastal flood analysis than calendar years.\n",
        "\n",
        "---\n",
        "\n",
        "# Barrier Closures\n",
        "\n",
        "This section analyzes past closures of the Thames barrier. The analysis:\n",
        "\n",
        "1. Loads barrier closure dates from an Excel file\n",
        "2. Counts closures per water year (July 1 to July 1)\n",
        "3. Calculates statistics (min, mean, max, total closures)\n",
        "4. Creates a bar chart visualization\n"
      ],
      "id": "1968aab0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-master1-thames\n",
        "#| include: true\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Configuration - years from 1986 to 2024\n",
        "Y = list(range(1986, 2025))  # [1986, 1987, ..., 2024]\n",
        "\n",
        "# Output directory\n",
        "output_dir = 'output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Analysis configuration:\")\n",
        "print(f\"  Water years: {Y[0]}/{str(Y[0]+1)[2:]} to {Y[-1]}/{str(Y[-1]+1)[2:]} ({len(Y)} years)\")"
      ],
      "id": "setup-master1-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-closures-thames\n",
        "#| include: true\n",
        "\n",
        "# 1. Observed closure data - Thames Barrier\n",
        "data_dir = '../2_DATA/1_BARRIER_CLOSURES'\n",
        "excel_file = os.path.join(data_dir, 'Thames_Barrier_Past_Closures_2024.xlsx')\n",
        "df = pd.read_excel(excel_file, sheet_name='Closures')\n",
        "\n",
        "# Extract closure dates from column 2 (index 1)\n",
        "closure_dates_col = df.iloc[:, 1]  # Column 2 (0-indexed)\n",
        "\n",
        "# Convert dates: pandas.read_excel automatically converts Excel dates to datetime objects\n",
        "OCD = [d.to_pydatetime() if isinstance(d, pd.Timestamp) else d \n",
        "       for d in closure_dates_col if pd.notna(d)]\n",
        "\n",
        "print(f\"Loaded {len(OCD)} closure dates\")\n",
        "if len(OCD) > 0:\n",
        "    print(f\"  First closure: {OCD[0]}\")\n",
        "    print(f\"  Last closure: {OCD[-1]}\")"
      ],
      "id": "load-closures-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n"
      ],
      "id": "1af56257"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: count-closures-thames\n",
        "#| include: true\n",
        "\n",
        "# 2. Count closures per water year (July 1 to July 1)\n",
        "OCS = []  # Will store [index, year, year+1, num_closures]\n",
        "YT = []   # Will store year labels like \"1986/87\"\n",
        "\n",
        "for co, y in enumerate(Y, start=1):\n",
        "    # Find closures between July 1 of year y and July 1 of year y+1\n",
        "    start_date = datetime(y, 7, 1, 0, 0, 0)\n",
        "    end_date = datetime(y + 1, 7, 1, 0, 0, 0)\n",
        "    \n",
        "    # Count closures in this water year\n",
        "    closures_in_year = [d for d in OCD if start_date <= d < end_date]\n",
        "    num_closures = len(closures_in_year)\n",
        "    \n",
        "    OCS.append([co, y, y + 1, num_closures])\n",
        "    \n",
        "    # Create year label (e.g., \"1986/87\")\n",
        "    year_str = str(y + 1)\n",
        "    YT.append(f\"{y}/{year_str[2:]}\")\n",
        "\n",
        "OCS = np.array(OCS)\n",
        "\n",
        "print(f\"\\nClosures per water year calculated for {len(OCS)} years\")\n",
        "print(f\"  Total closures: {np.sum(OCS[:, 3])}\")"
      ],
      "id": "count-closures-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: statistics-thames\n",
        "#| include: true\n",
        "\n",
        "# 3. Calculate statistics\n",
        "E = np.array([\n",
        "    np.min(OCS[:, 3]),      # Minimum closures per year\n",
        "    np.mean(OCS[:, 3]),     # Mean closures per year\n",
        "    np.max(OCS[:, 3]),      # Maximum closures per year\n",
        "    np.sum(OCS[:, 3])       # Total closures\n",
        "])\n",
        "\n",
        "print(f\"\\nClosure statistics:\")\n",
        "print(f\"  Min per year: {E[0]:.1f}\")\n",
        "print(f\"  Mean per year: {E[1]:.2f}\")\n",
        "print(f\"  Max per year: {E[2]:.1f}\")\n",
        "print(f\"  Total: {E[3]:.0f}\")"
      ],
      "id": "statistics-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: save-master1-thames\n",
        "#| include: true\n",
        "\n",
        "# 4. Save data\n",
        "output_file = os.path.join(output_dir, 'mast1_thames.pkl')\n",
        "with open(output_file, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'OCD': OCD,\n",
        "        'OCS': OCS,\n",
        "        'E': E,\n",
        "        'YT': YT\n",
        "    }, f)\n",
        "print(f\"\\nData saved to {output_file}\")"
      ],
      "id": "save-master1-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n",
        "\n",
        "This bar chart shows the number of barrier closures per water year from 1986/87 to 2024/25. The Thames Barrier closes when water levels exceed a threshold, typically during storm surge events.\n"
      ],
      "id": "18d3ac29"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 6
      },
      "source": [
        "#| label: plot-closures-thames\n",
        "#| fig-cap: Number of Thames Barrier closures per water year (July 1 to June 30), 1986-2024\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.bar(OCS[:, 0], OCS[:, 3], color='black')\n",
        "ax.set_xlim(0.2, len(OCS) + 0.8)\n",
        "ax.set_xticks(range(1, len(OCS) + 1))\n",
        "ax.set_xticklabels(YT, rotation=90)\n",
        "# Note: y-axis limit may need adjustment based on actual data\n",
        "max_closures = int(np.max(OCS[:, 3])) + 1\n",
        "ax.set_ylim(0, max_closures)\n",
        "ax.set_yticks(range(0, max_closures + 1, max(1, max_closures // 10)))\n",
        "ax.set_ylabel('Number of closures', fontweight='bold', fontsize=18)\n",
        "ax.set_title('Thames Barrier', fontweight='bold', fontsize=18)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.tick_params(labelsize=16)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "fig_file = os.path.join(output_dir, 'master1_thames_closures.png')\n",
        "plt.savefig(fig_file, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to {fig_file}\")"
      ],
      "id": "plot-closures-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following table lists all barrier closure dates, which correspond to storm events that triggered the Thames Barrier.\n"
      ],
      "id": "5463bc8b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: table-storms-thames\n",
        "#| tbl-cap: Complete list of Thames Barrier closures (storm events), 1986-2024\n",
        "\n",
        "# Create DataFrame with closure dates\n",
        "storms_df = pd.DataFrame({\n",
        "    'Closure Date': [d.strftime('%Y-%m-%d %H:%M') if isinstance(d, datetime) else str(d) for d in OCD],\n",
        "    'Year': [d.year if isinstance(d, datetime) else None for d in OCD],\n",
        "    'Month': [d.strftime('%B') if isinstance(d, datetime) else None for d in OCD],\n",
        "    'YearMonth': [(d.year, d.month) if isinstance(d, datetime) else None for d in OCD]\n",
        "})\n",
        "\n",
        "# Add water year information\n",
        "def get_water_year(date):\n",
        "    \"\"\"Determine water year (July 1 to June 30)\"\"\"\n",
        "    if isinstance(date, datetime):\n",
        "        if date.month >= 7:\n",
        "            return f\"{date.year}/{str(date.year + 1)[2:]}\"\n",
        "        else:\n",
        "            return f\"{date.year - 1}/{str(date.year)[2:]}\"\n",
        "    return None\n",
        "\n",
        "storms_df['Water Year'] = [get_water_year(d) for d in OCD]\n",
        "\n",
        "# Create index that groups storms by year and month\n",
        "# Storms in the same year and month get the same index\n",
        "unique_year_months = storms_df['YearMonth'].unique()\n",
        "year_month_to_index = {ym: idx + 1 for idx, ym in enumerate(sorted(unique_year_months))}\n",
        "storms_df['Event'] = storms_df['YearMonth'].map(year_month_to_index)\n",
        "\n",
        "# Reorder columns (Index first, then remove YearMonth helper column)\n",
        "storms_df = storms_df[['Event', 'Closure Date', 'Water Year', 'Year', 'Month']]\n",
        "\n",
        "# Display table\n",
        "print(f\"\\nTotal number of closures: {len(storms_df)}\")\n",
        "storms_df"
      ],
      "id": "table-storms-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Tide Gauge Data Processing\n",
        "\n",
        "This section loads and processes raw tide gauge data from the Thames estuary. The analysis uses the **Sheerness tide gauge** data from the GESLA4 (Global Extreme Sea Level Analysis) dataset, which is located near the Thames Barrier at coordinates 51.445639°N, 0.743361°E. The Sheerness gauge provides high-quality data from the British Oceanographic Data Centre (BODC) covering the period from 1952 to 2025.\n",
        "\n",
        "The analysis:\n",
        "\n",
        "1. Loads data from the GESLA4 format file (`sheerness-she-gbr-bodc`)\n",
        "2. Parses the GESLA4 format (Date, Time, Sea level, QC flag, Use flag)\n",
        "3. Filters data to the analysis period (1986-2023) and quality-controlled values\n",
        "4. Interpolates the data to 10-minute intervals to match the analysis requirements\n",
        "5. Creates a visualization of the complete water level time series\n",
        "\n",
        "The GESLA4 format uses Admiralty Chart Datum (ACD) as the vertical reference. The data is provided at 15-minute intervals in the original file, which is interpolated to 10-minute intervals for consistency with the Eastern Scheldt analysis workflow. Missing values are indicated by -99.9999 in the GESLA4 format and are filtered out during processing.\n"
      ],
      "id": "127a2835"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-master2-thames\n",
        "#| include: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Configuration\n",
        "# Use GESLA4 data from RTides directory\n",
        "gesla_dir = '../../RTides/data/GESLA4_ALL'\n",
        "data_dir = '../2_DATA/2_TIDE_GAUGE/TB'\n",
        "output_dir = 'output'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"GESLA4 data directory: {gesla_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")"
      ],
      "id": "setup-master2-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section loads the Sheerness tide gauge data from the GESLA4 dataset. The GESLA4 format is a standardized global sea level dataset that includes quality control flags and metadata. The Sheerness gauge is located on the Isle of Sheppey in the Thames estuary, approximately 50 km downstream from the Thames Barrier, making it an appropriate reference for barrier closure analysis.\n",
        "\n",
        "The data loading process:\n",
        "- Reads the GESLA4 file format, skipping header lines (starting with `#`)\n",
        "- Parses date/time strings and converts them to datetime objects\n",
        "- Extracts sea level values (in meters) and quality control flags\n",
        "- Filters to only include data with `use_flag == 1` (recommended for analysis)\n",
        "- Removes missing values (indicated by -99.9999)\n",
        "- Filters to the analysis period (1986-2023)\n",
        "- Interpolates from the original 15-minute intervals to 10-minute intervals using nearest-neighbor interpolation with a 15-minute tolerance\n",
        "\n",
        "The resulting time series provides continuous water level data at 10-minute intervals for the entire analysis period.\n"
      ],
      "id": "2da831b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-tide-gauge-thames\n",
        "#| include: true\n",
        "\n",
        "# Load GESLA4 format tide gauge data for Thames (Sheerness gauge)\n",
        "file_in = os.path.join(gesla_dir, 'sheerness-she-gbr-bodc')\n",
        "\n",
        "if not os.path.exists(file_in):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Required file {file_in} not found. \"\n",
        "        f\"Please ensure the GESLA4 data file exists.\"\n",
        "    )\n",
        "\n",
        "# Read GESLA4 file\n",
        "# Format: Date (yyyy/mm/dd), Time (hh:mm:ss), Sea level (m), QC flag, Use flag\n",
        "# Missing values are -99.9999\n",
        "data_lines = []\n",
        "with open(file_in, 'r') as f:\n",
        "    for line in f:\n",
        "        # Skip header lines (start with #)\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        # Skip empty lines\n",
        "        if line.strip():\n",
        "            data_lines.append(line.strip().split())\n",
        "\n",
        "# Parse data\n",
        "dates = []\n",
        "times = []\n",
        "water_levels = []\n",
        "use_flags = []\n",
        "\n",
        "for line in data_lines:\n",
        "    if len(line) >= 5:\n",
        "        date_str = line[0]  # yyyy/mm/dd\n",
        "        time_str = line[1]  # hh:mm:ss\n",
        "        wl_str = line[2]    # sea level (m)\n",
        "        qc_flag = line[3]  # QC flag\n",
        "        use_flag = line[4] # use flag\n",
        "        \n",
        "        # Parse datetime\n",
        "        dt_str = f\"{date_str} {time_str}\"\n",
        "        dt = datetime.strptime(dt_str, '%Y/%m/%d %H:%M:%S')\n",
        "        dates.append(dt)\n",
        "        \n",
        "        # Parse water level\n",
        "        try:\n",
        "            wl = float(wl_str)\n",
        "            # Check for missing values (-99.9999)\n",
        "            if wl == -99.9999 or abs(wl) > 100:  # Also filter unrealistic values\n",
        "                wl = np.nan\n",
        "        except ValueError:\n",
        "            wl = np.nan\n",
        "        \n",
        "        water_levels.append(wl)\n",
        "        use_flags.append(int(use_flag))\n",
        "\n",
        "# Convert to numpy arrays\n",
        "dates = np.array(dates)\n",
        "water_levels = np.array(water_levels)\n",
        "\n",
        "# Filter to use only data with use_flag == 1\n",
        "use_mask = np.array(use_flags) == 1\n",
        "dates_clean = dates[use_mask]\n",
        "water_levels_clean = water_levels[use_mask]\n",
        "\n",
        "# Filter to analysis period: 1986-2023\n",
        "start_date = datetime(1986, 1, 1, 0, 0, 0)\n",
        "end_date = datetime(2023, 12, 31, 23, 59, 59)\n",
        "mask_period = (dates_clean >= start_date) & (dates_clean <= end_date)\n",
        "dates_period = dates_clean[mask_period]\n",
        "water_levels_period = water_levels_clean[mask_period]\n",
        "\n",
        "# Create 10-minute interval time series for the period\n",
        "TSP = pd.date_range(start=start_date, end=end_date, freq='10min').to_pydatetime()\n",
        "\n",
        "# Interpolate water levels to 10-minute intervals using pandas\n",
        "# Create Series with original timestamps\n",
        "wl_series = pd.Series(water_levels_period, index=pd.DatetimeIndex(dates_period))\n",
        "# Reindex to 10-minute intervals and interpolate\n",
        "wl_series_10min = wl_series.reindex(pd.DatetimeIndex(TSP), method='nearest', \n",
        "                                     tolerance=pd.Timedelta(minutes=15))\n",
        "WLP = wl_series_10min.values\n",
        "\n",
        "print(f\"Loaded Sheerness tide gauge (GESLA4):\")\n",
        "print(f\"  Original data points: {len(dates):,}\")\n",
        "print(f\"  Data in period 1986-2023: {len(dates_period):,}\")\n",
        "print(f\"  Interpolated to 10-minute intervals: {len(TSP):,} points\")\n",
        "print(f\"  Start: {TSP[0]}\")\n",
        "print(f\"  End: {TSP[-1]}\")\n",
        "print(f\"  Valid data: {np.sum(~np.isnan(WLP)):,} points ({100*np.sum(~np.isnan(WLP))/len(WLP):.1f}%)\")"
      ],
      "id": "load-tide-gauge-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results (Part 2)\n",
        "\n",
        "Save the combined time series to a pickle file for use in subsequent analyses.\n"
      ],
      "id": "e717035d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: save-master2-thames\n",
        "#| include: true\n",
        "\n",
        "# Save data\n",
        "output_file = os.path.join(output_dir, 'mast2_thames.pkl')\n",
        "with open(output_file, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'TSP': TSP,\n",
        "        'WLP': WLP,\n",
        "        'TSCHECK': TSP  # Reference time series\n",
        "    }, f)\n",
        "print(f\"\\nData saved to {output_file}\")"
      ],
      "id": "save-master2-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Part 2)\n",
        "\n",
        "This figure shows the combined tide gauge water level time series from 1986 to 2023 at 10-minute intervals. The data shows tidal variations, storm surges, and long-term water level patterns over the period.\n"
      ],
      "id": "f91c5f71"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 6
      },
      "source": [
        "#| label: plot-time-series-thames\n",
        "#| fig-cap: Combined tide gauge water level time series for the Thames, 1986-2023. Data at 10-minute intervals.\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.plot(TSP, WLP, 'b', linewidth=0.5)\n",
        "ax.set_xlabel('Date', fontweight='bold', fontsize=20)\n",
        "ax.set_ylabel('Water level (m NAP)', fontweight='bold', fontsize=20)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.tick_params(labelsize=16)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "fig_file = os.path.join(output_dir, 'master2_thames_tide_gauge.png')\n",
        "plt.savefig(fig_file, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to {fig_file}\")"
      ],
      "id": "plot-time-series-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Tidal Analysis\n",
        "\n",
        "This section performs harmonic tidal analysis on tide gauge data from the Thames. The analysis:\n",
        "\n",
        "1. Calculates data quality for each year (1986-2023)\n",
        "2. Performs harmonic tidal decomposition using `pytides` (replacing MATLAB's `t_tide`)\n",
        "3. Generates tidal predictions for all years\n",
        "4. Compares observed water levels with predicted astronomical tides\n",
        "\n",
        "The predicted tides represent only the astronomical component, while observed water levels include both tides and meteorological effects (storm surges, wind setup, etc.).\n",
        "\n",
        "## Setup and Configuration\n"
      ],
      "id": "2fc5b61c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-master3-thames\n",
        "#| include: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from pytides.tide import Tide\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "Y = list(range(1986, 2024))  # Years 1986 to 2023\n",
        "th = 60  # Data quality threshold (percentage)\n",
        "lat = 51.5  # Latitude for tidal analysis (Thames Barrier approximate location)\n",
        "output_dir = 'output'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Analysis configuration:\")\n",
        "print(f\"  Years: {Y[0]} to {Y[-1]} ({len(Y)} years)\")\n",
        "print(f\"  Data quality threshold: {th}%\")\n",
        "print(f\"  Latitude: {lat}°\")"
      ],
      "id": "setup-master3-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Tide Gauge Data\n"
      ],
      "id": "5a6c0dd9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-data-master3-thames\n",
        "#| include: true\n",
        "\n",
        "print(\"Loading tide gauge data...\")\n",
        "mast2_file = os.path.join(output_dir, 'mast2_thames.pkl')\n",
        "if not os.path.exists(mast2_file):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Required file {mast2_file} not found. \"\n",
        "        \"Please run Part 2 (Tide Gauge Data Processing) first to generate the required data file.\"\n",
        "    )\n",
        "with open(mast2_file, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    TSP = data['TSP']\n",
        "    WLP = data['WLP']\n",
        "\n",
        "# Convert to numpy arrays if needed\n",
        "TSP = np.array(TSP)\n",
        "WLP = np.array(WLP)\n",
        "\n",
        "print(f\"Loaded {len(TSP):,} data points\")\n",
        "print(f\"  Start: {TSP[0]}\")\n",
        "print(f\"  End: {TSP[-1]}\")\n",
        "print(f\"  Valid data: {np.sum(~np.isnan(WLP)):,} points ({100*np.sum(~np.isnan(WLP))/len(WLP):.1f}%)\")"
      ],
      "id": "load-data-master3-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Data Quality Per Year\n"
      ],
      "id": "c652cf20"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-quality-thames\n",
        "#| include: true\n",
        "\n",
        "print(\"\\nCalculating data quality per year...\")\n",
        "DQ = []\n",
        "\n",
        "for y in Y:\n",
        "    # Find data points in this calendar year (Jan 1 to Jan 1 next year)\n",
        "    start_date = datetime(y, 1, 1, 0, 0, 0)\n",
        "    end_date = datetime(y + 1, 1, 1, 0, 0, 0)\n",
        "    mask = (TSP >= start_date) & (TSP < end_date)\n",
        "    j = np.where(mask)[0]\n",
        "    \n",
        "    if len(j) == 0:\n",
        "        quality = 0\n",
        "    else:\n",
        "        # Count non-NaN values\n",
        "        k = np.where(~np.isnan(WLP[j]))[0]\n",
        "        quality = (len(k) / len(j)) * 100\n",
        "    \n",
        "    # Initialize with 3 columns: [year, quality, reference_year]\n",
        "    # reference_year will be filled in during tidal analysis\n",
        "    DQ.append([y, quality, np.nan])\n",
        "\n",
        "DQ = np.array(DQ)\n",
        "\n",
        "# Display summary statistics\n",
        "print(f\"\\nData quality summary:\")\n",
        "print(f\"  Range: {np.min(DQ[:, 1]):.1f}% to {np.max(DQ[:, 1]):.1f}%\")\n",
        "print(f\"  Mean: {np.mean(DQ[:, 1]):.1f}%\")\n",
        "print(f\"  Years with quality >= {th}%: {np.sum(DQ[:, 1] >= th)}/{len(Y)}\")"
      ],
      "id": "data-quality-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tidal Analysis and Prediction\n",
        "\n",
        "For each target year, the analysis determines a reference year, extracts data, performs harmonic decomposition, and generates predictions.\n"
      ],
      "id": "b03c4340"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tidal-analysis-thames\n",
        "#| include: true\n",
        "\n",
        "print(\"\\nPerforming tidal analysis and prediction...\")\n",
        "TSP2 = []\n",
        "TIP = []\n",
        "\n",
        "for co, y in enumerate(Y):\n",
        "    print(f\"  Processing year {y} ({co+1}/{len(Y)})...\")\n",
        "    \n",
        "    # Determine reference year\n",
        "    if DQ[co, 1] >= th:\n",
        "        # Use target year as reference\n",
        "        yr = y\n",
        "        DQ[co, 2] = yr\n",
        "    else:\n",
        "        # Find nearest year with quality >= threshold\n",
        "        # Calculate distances from target year\n",
        "        distances = np.abs(DQ[:, 0] - y)\n",
        "        \n",
        "        # Filter to only years with quality >= threshold\n",
        "        good_mask = DQ[:, 1] >= th\n",
        "        \n",
        "        if np.any(good_mask):\n",
        "            # Get distances for good years only\n",
        "            good_distances = distances[good_mask]\n",
        "            good_indices = np.where(good_mask)[0]\n",
        "            \n",
        "            # Find nearest good year\n",
        "            nearest_idx = good_indices[np.argmin(good_distances)]\n",
        "            yr = int(DQ[nearest_idx, 0])\n",
        "        else:\n",
        "            # Fallback: use year with best quality\n",
        "            best_idx = np.argmax(DQ[:, 1])\n",
        "            yr = int(DQ[best_idx, 0])\n",
        "        \n",
        "        DQ[co, 2] = yr\n",
        "    \n",
        "    # Extract reference year data (1 year + 1 day for analysis)\n",
        "    ref_start = datetime(yr, 1, 1, 0, 0, 0)\n",
        "    ref_end = datetime(yr + 1, 1, 2, 0, 0, 0)  # +1 day\n",
        "    \n",
        "    mask_ref = (TSP >= ref_start) & (TSP < ref_end)\n",
        "    j_ref = np.where(mask_ref)[0]\n",
        "    \n",
        "    if len(j_ref) == 0:\n",
        "        print(f\"    Warning: No data found for reference year {yr}\")\n",
        "        continue\n",
        "    \n",
        "    # Get water levels and times for reference year\n",
        "    WLP_ref = WLP[j_ref]\n",
        "    TSP_ref = TSP[j_ref]\n",
        "    \n",
        "    # Remove NaN values for pytides analysis\n",
        "    valid_mask = ~np.isnan(WLP_ref)\n",
        "    WLP_clean = WLP_ref[valid_mask]\n",
        "    TSP_clean = TSP_ref[valid_mask]\n",
        "    \n",
        "    if len(WLP_clean) < 1000:  # Need sufficient data for analysis\n",
        "        print(f\"    Warning: Insufficient data for reference year {yr} ({len(WLP_clean)} points)\")\n",
        "        continue\n",
        "    \n",
        "    # Perform tidal analysis using pytides\n",
        "    try:\n",
        "        tide_model = Tide.decompose(\n",
        "            heights=WLP_clean,\n",
        "            t=TSP_clean\n",
        "        )\n",
        "        print(f\"    Analyzed {len(WLP_clean):,} points from reference year {yr}\")\n",
        "    except Exception as e:\n",
        "        print(f\"    Error in tidal analysis for year {y}: {e}\")\n",
        "        continue\n",
        "    \n",
        "    # Generate prediction timestamps for target year (10-minute intervals)\n",
        "    pred_start = datetime(y, 1, 1, 0, 0, 0)\n",
        "    pred_end = datetime(y, 12, 31, 23, 50, 0)\n",
        "    tsp2 = pd.date_range(start=pred_start, end=pred_end, freq='10min').to_pydatetime()\n",
        "    \n",
        "    # Predict tides\n",
        "    try:\n",
        "        tip = tide_model.at(tsp2)\n",
        "        TIP.extend(tip)\n",
        "        TSP2.extend(tsp2)\n",
        "        print(f\"    Predicted {len(tip):,} points for year {y}\")\n",
        "    except Exception as e:\n",
        "        print(f\"    Error in prediction for year {y}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Convert to numpy arrays\n",
        "TSP2 = np.array(TSP2)\n",
        "TIP = np.array(TIP)\n",
        "\n",
        "print(f\"\\nTotal predictions: {len(TIP):,} points\")\n",
        "if len(TIP) > 0:\n",
        "    print(f\"  Start: {TSP2[0]}\")\n",
        "    print(f\"  End: {TSP2[-1]}\")"
      ],
      "id": "tidal-analysis-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results (Part 3)\n"
      ],
      "id": "9f672eaf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: save-master3-thames\n",
        "#| include: true\n",
        "\n",
        "output_file = os.path.join(output_dir, 'mast3_thames.pkl')\n",
        "with open(output_file, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'TSP': TSP,\n",
        "        'WLP': WLP,\n",
        "        'TIP': TIP,\n",
        "        'TSP2': TSP2,\n",
        "        'DQ': DQ\n",
        "    }, f)\n",
        "print(f\"Data saved to {output_file}\")"
      ],
      "id": "save-master3-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Part 3)\n",
        "\n",
        "This figure compares observed water levels (blue) with predicted astronomical tides (red) from harmonic analysis. The predicted tides represent the astronomical component only, while observed water levels include both tides and meteorological effects.\n"
      ],
      "id": "0ebae7a5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 6
      },
      "source": [
        "#| label: plot-comparison-thames\n",
        "#| fig-cap: Comparison of observed water levels (blue) and predicted astronomical tides (red) for the Thames, 1986-2023\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.plot(TSP2, TIP, 'r', linewidth=0.5, label='Predicted tide', alpha=0.7)\n",
        "ax.plot(TSP, WLP, 'b', linewidth=0.5, label='Observed water level', alpha=0.7)\n",
        "ax.set_xlabel('Date', fontweight='bold', fontsize=16)\n",
        "ax.set_ylabel('Level (m NAP)', fontweight='bold', fontsize=16)\n",
        "ax.legend(fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.tick_params(labelsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "fig_file = os.path.join(output_dir, 'master3_thames_tidal_analysis.png')\n",
        "plt.savefig(fig_file, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to {fig_file}\")"
      ],
      "id": "plot-comparison-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Predicted High Waters and Barrier Closures\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This section plots time-series of predicted high waters and barrier closures for the Thames. The analysis:\n",
        "\n",
        "1. Loads barrier closure dates and tide gauge data from previous analyses\n",
        "2. Creates a visualization showing:\n",
        "   - Barrier closure dates as vertical dashed lines\n",
        "   - Predicted astronomical tides (TIP)\n",
        "   - Observed water levels (WLP)\n",
        "   - The difference between observed and predicted levels (surge component)\n",
        "\n",
        "This visualization helps identify when barrier closures occurred relative to predicted high waters and actual water levels.\n",
        "\n",
        "## Setup and Configuration\n"
      ],
      "id": "cefb1977"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-master4-thames\n",
        "#| include: true\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Output directory\n",
        "output_dir = 'output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Analysis configuration:\")\n",
        "print(f\"  Output directory: {output_dir}\")"
      ],
      "id": "setup-master4-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ],
      "id": "53613487"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-data-master4-thames\n",
        "#| include: true\n",
        "\n",
        "# Load barrier closure data from master1\n",
        "print(\"Loading barrier closure data...\")\n",
        "mast1_file = os.path.join(output_dir, 'mast1_thames.pkl')\n",
        "if not os.path.exists(mast1_file):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Required file {mast1_file} not found. \"\n",
        "        \"Please run Part 1 (Barrier Closure Analysis) first to generate the required data file.\"\n",
        "    )\n",
        "with open(mast1_file, 'rb') as f:\n",
        "    data1 = pickle.load(f)\n",
        "    OCD = data1['OCD']  # Observed closure dates\n",
        "\n",
        "# Load tide gauge and tidal prediction data from master3\n",
        "print(\"Loading tide gauge and tidal prediction data...\")\n",
        "mast3_file = os.path.join(output_dir, 'mast3_thames.pkl')\n",
        "if not os.path.exists(mast3_file):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Required file {mast3_file} not found. \"\n",
        "        \"Please run Part 1, Part 2, and Part 3 first to generate the required data files.\"\n",
        "    )\n",
        "with open(mast3_file, 'rb') as f:\n",
        "    data3 = pickle.load(f)\n",
        "    TSP = data3['TSP']  # Time series for observed water levels\n",
        "    TSP2 = data3['TSP2']  # Time series for predictions\n",
        "    TIP = data3['TIP']  # Predicted tides\n",
        "    WLP = data3['WLP']  # Observed water levels\n",
        "\n",
        "# Convert to numpy arrays if needed\n",
        "OCD = np.array(OCD)\n",
        "TSP = np.array(TSP)\n",
        "TSP2 = np.array(TSP2)\n",
        "TIP = np.array(TIP)\n",
        "WLP = np.array(WLP)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Closure dates: {len(OCD)} closures\")\n",
        "if len(OCD) > 0:\n",
        "    print(f\"    First closure: {OCD[0]}\")\n",
        "    print(f\"    Last closure: {OCD[-1]}\")\n",
        "print(f\"  Time series points (observed): {len(TSP):,}\")\n",
        "print(f\"  Time series points (predictions): {len(TSP2):,}\")\n",
        "print(f\"  Predicted tides: {len(TIP):,}\")\n",
        "print(f\"  Observed water levels: {len(WLP):,}\")"
      ],
      "id": "load-data-master4-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Figure - Predicted High Waters and Closures\n",
        "\n",
        "This figure shows predicted astronomical tides (red), observed water levels (blue), the difference between them (green), and barrier closure dates (vertical dashed magenta lines). The difference (WLP-TIP) represents the non-tidal component, primarily storm surge.\n"
      ],
      "id": "b9995a44"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 8
      },
      "source": [
        "#| label: plot-predicted-high-waters-thames\n",
        "#| fig-cap: Predicted high waters, observed water levels, and barrier closures for the Thames\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Plot vertical lines for barrier closure dates\n",
        "for i in range(len(OCD)):\n",
        "    ax.axvline(OCD[i], color='m', linestyle='--', linewidth=2, alpha=0.7)\n",
        "\n",
        "# Check if we have predictions\n",
        "if len(TIP) > 0 and len(TSP2) > 0:\n",
        "    # Plot predicted tides (TIP) - use TSP2 for time axis\n",
        "    ax.plot(TSP2, TIP, 'r', linewidth=1, label='Predicted tide (TIP)', alpha=0.8)\n",
        "    \n",
        "    # For observed water levels, plot the full time series\n",
        "    ax.plot(TSP, WLP, 'b', linewidth=1, label='Observed water level (WLP)', alpha=0.8)\n",
        "    \n",
        "    # For surge calculation, interpolate TIP to match TSP timestamps using pandas\n",
        "    # Find overlapping time period\n",
        "    mask_overlap = (TSP >= TSP2[0]) & (TSP <= TSP2[-1])\n",
        "    if np.any(mask_overlap):\n",
        "        TSP_overlap = TSP[mask_overlap]\n",
        "        WLP_overlap = WLP[mask_overlap]\n",
        "        # Use pandas for interpolation\n",
        "        df_tip = pd.Series(TIP, index=pd.DatetimeIndex(TSP2))\n",
        "        # Reindex to overlap timestamps and interpolate\n",
        "        tip_interp = df_tip.reindex(pd.DatetimeIndex(TSP_overlap), method='nearest', \n",
        "                                    tolerance=pd.Timedelta(minutes=15))\n",
        "        # Calculate surge where we have both values\n",
        "        valid_mask = ~tip_interp.isna()\n",
        "        if np.any(valid_mask):\n",
        "            surge = WLP_overlap[valid_mask] - tip_interp.values[valid_mask]\n",
        "            ax.plot(TSP_overlap[valid_mask], surge, 'g', \n",
        "                   linewidth=1, label='Surge (WLP - TIP)', alpha=0.8)\n",
        "else:\n",
        "    # If no predictions, just plot observed water levels\n",
        "    print(\"Warning: No tidal predictions available. Plotting only observed water levels.\")\n",
        "    ax.plot(TSP, WLP, 'b', linewidth=1, label='Observed water level (WLP)', alpha=0.8)\n",
        "\n",
        "# Formatting\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlabel('Date', fontweight='bold', fontsize=16)\n",
        "ax.set_ylabel('Level (m)', fontweight='bold', fontsize=16)\n",
        "ax.set_ylim(-3, 4)\n",
        "ax.legend(fontsize=14, loc='best')\n",
        "ax.tick_params(labelsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save figure\n",
        "fig_file = os.path.join(output_dir, 'master4_thames_predicted_high_waters.png')\n",
        "plt.savefig(fig_file, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to {fig_file}\")"
      ],
      "id": "plot-predicted-high-waters-thames",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "This complete analysis workflow has processed data from 1986 to 2024 for the Thames barrier system. Key results from each part:\n",
        "\n",
        "## Part 1: Barrier Closure Analysis\n",
        "- **Total closures**: Recorded across water years 1986/87 to 2024/25\n",
        "- **Annual statistics**: Minimum, mean, and maximum closures per water year\n",
        "- **Temporal patterns**: Variability in closure frequency over time\n",
        "\n",
        "## Part 2: Tide Gauge Data Processing\n",
        "- **Combined time series**: 1986-2023 at 10-minute intervals\n",
        "- **Data sources**: Available Thames tide gauge measurements\n",
        "- **Data quality**: Percentage of valid data points across the time series\n",
        "\n",
        "## Part 3: Tidal Analysis\n",
        "- **Data quality**: Calculated for each year to determine suitable reference years\n",
        "- **Harmonic analysis**: Performed using `pytides` (Python equivalent of MATLAB's `t_tide`)\n",
        "- **Predictions**: Generated at 10-minute intervals for the entire period\n",
        "- **Surge calculation**: The difference between observed and predicted water levels represents the non-tidal component (surge)\n",
        "\n",
        "## Part 4: Visualization\n",
        "- **Closure timing**: When closures occurred relative to predicted high waters\n",
        "- **Surge contribution**: The non-tidal component shows how much storm surge contributed to water levels\n",
        "- **Tidal vs. meteorological effects**: The difference between observed and predicted levels highlights meteorological forcing\n",
        "\n",
        "The complete workflow provides a foundation for understanding barrier closure patterns, water level variability, and storm surge dynamics in the Thames estuary. The results can be used for further analysis of individual closure events, surge characteristics, and long-term trends."
      ],
      "id": "e9661fbe"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/miniconda3/envs/objective1/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}